{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/smallnorb-5x46789x9x18x6x2x96x96-training-dat.mat.gz\n",
    "#https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/smallnorb-5x46789x9x18x6x2x96x96-training-cat.mat.gz\n",
    "#https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/smallnorb-5x46789x9x18x6x2x96x96-training-info.mat.gz\n",
    "#https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat.gz\n",
    "#https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/smallnorb-5x01235x9x18x6x2x96x96-testing-cat.mat.gz\n",
    "#https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/smallnorb-5x01235x9x18x6x2x96x96-testing-info.mat.gz    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "from tqdm import tqdm\n",
    "from os import makedirs\n",
    "from os.path import join\n",
    "from os.path import exists\n",
    "from itertools import groupby\n",
    "\n",
    "\n",
    "class SmallNORBExample:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.image_lt  = None\n",
    "        self.image_rt  = None\n",
    "        self.category  = None\n",
    "        self.instance  = None\n",
    "        self.elevation = None\n",
    "        self.azimuth   = None\n",
    "        self.lighting  = None\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.category < other.category or \\\n",
    "                (self.category == other.category and self.instance < other.instance)\n",
    "\n",
    "    def show(self, subplots):\n",
    "        fig, axes = subplots\n",
    "        fig.suptitle(\n",
    "            'Category: {:02d} - Instance: {:02d} - Elevation: {:02d} - Azimuth: {:02d} - Lighting: {:02d}'.format(\n",
    "                self.category, self.instance, self.elevation, self.azimuth, self.lighting))\n",
    "        axes[0].imshow(self.image_lt, cmap='gray')\n",
    "        axes[1].imshow(self.image_rt, cmap='gray')\n",
    "\n",
    "    @property\n",
    "    def pose(self):\n",
    "        return np.array([self.elevation, self.azimuth, self.lighting], dtype=np.float32)\n",
    "\n",
    "\n",
    "class SmallNORBDataset:\n",
    "\n",
    "    # Number of examples in both train and test set\n",
    "    n_examples = 24300\n",
    "\n",
    "    # Categories present in small NORB dataset\n",
    "    categories = ['animal', 'human', 'airplane', 'truck', 'car']\n",
    "\n",
    "    def __init__(self, dataset_root):\n",
    "        \"\"\"\n",
    "        Initialize small NORB dataset wrapper\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset_root: str\n",
    "            Path to directory where small NORB archives have been extracted.\n",
    "        \"\"\"\n",
    "\n",
    "        self.dataset_root = dataset_root\n",
    "        self.initialized  = False\n",
    "\n",
    "        # Store path for each file in small NORB dataset (for compatibility the original filename is kept)\n",
    "        self.dataset_files = {\n",
    "            'train': {\n",
    "                'cat':  join(self.dataset_root, 'smallnorb-5x46789x9x18x6x2x96x96-training-cat.mat'),\n",
    "                'info': join(self.dataset_root, 'smallnorb-5x46789x9x18x6x2x96x96-training-info.mat'),\n",
    "                'dat':  join(self.dataset_root, 'smallnorb-5x46789x9x18x6x2x96x96-training-dat.mat')\n",
    "            },\n",
    "            'test':  {\n",
    "                'cat':  join(self.dataset_root, 'smallnorb-5x01235x9x18x6x2x96x96-testing-cat.mat'),\n",
    "                'info': join(self.dataset_root, 'smallnorb-5x01235x9x18x6x2x96x96-testing-info.mat'),\n",
    "                'dat':  join(self.dataset_root, 'smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat')\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Initialize both train and test data structures\n",
    "        self.data = {\n",
    "            'train': [SmallNORBExample() for _ in range(SmallNORBDataset.n_examples)],\n",
    "            'test':  [SmallNORBExample() for _ in range(SmallNORBDataset.n_examples)]\n",
    "        }\n",
    "\n",
    "        # Fill data structures parsing dataset binary files\n",
    "        for data_split in ['train', 'test']:\n",
    "            self._fill_data_structures(data_split)\n",
    "\n",
    "        self.initialized = True\n",
    "\n",
    "    def explore_random_examples(self, dataset_split):\n",
    "        \"\"\"\n",
    "        Visualize random examples for dataset exploration purposes\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset_split: str\n",
    "            Dataset split, can be either 'train' or 'test'\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        if self.initialized:\n",
    "            subplots = plt.subplots(nrows=1, ncols=2)\n",
    "            for i in np.random.permutation(SmallNORBDataset.n_examples):\n",
    "                \n",
    "                self.data[dataset_split][i].show(subplots)\n",
    "                #plt.waitforbuttonpress()\n",
    "                plt.show()\n",
    "\n",
    "    def export_to_jpg(self, export_dir):\n",
    "        \"\"\"\n",
    "        Export all dataset images to `export_dir` directory\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        export_dir: str\n",
    "            Path to export directory (which is created if nonexistent)\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        if self.initialized:\n",
    "            print('Exporting images to {}...'.format(export_dir), end='', flush=True)\n",
    "            for split_name in ['train', 'test']:\n",
    "\n",
    "                split_dir = join(export_dir, split_name)\n",
    "                if not exists(split_dir):\n",
    "                    makedirs(split_dir)\n",
    "\n",
    "                for i, norb_example in enumerate(self.data[split_name]):\n",
    "\n",
    "                    category = SmallNORBDataset.categories[norb_example.category]\n",
    "                    instance = norb_example.instance\n",
    "\n",
    "                    image_lt_path = join(split_dir, '{:06d}_{}_{:02d}_lt.jpg'.format(i, category, instance))\n",
    "                    image_rt_path = join(split_dir, '{:06d}_{}_{:02d}_rt.jpg'.format(i, category, instance))\n",
    "\n",
    "                    scipy.misc.imsave(image_lt_path, norb_example.image_lt)\n",
    "                    scipy.misc.imsave(image_rt_path, norb_example.image_rt)\n",
    "            print('Done.')\n",
    "            \n",
    "    def get_XY(self, w, h):\n",
    "        \"\"\"\n",
    "        Export all dataset images to `export_dir` directory\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        export_dir: str\n",
    "            Path to export directory (which is created if nonexistent)\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        X = list()\n",
    "        y = list()\n",
    "        \n",
    "        if self.initialized:\n",
    "            #print('Exporting images to {}...'.format(export_dir), end='', flush=True)\n",
    "            for split_name in ['train', 'test']:\n",
    "\n",
    "                #split_dir = join(export_dir, split_name)\n",
    "                #if not exists(split_dir):\n",
    "                    #makedirs(split_dir)\n",
    "\n",
    "                for i, norb_example in enumerate(self.data[split_name]):\n",
    "\n",
    "                    category = SmallNORBDataset.categories[norb_example.category]\n",
    "                    instance = norb_example.instance\n",
    "\n",
    "                    #image_lt_path = join(split_dir, '{:06d}_{}_{:02d}_lt.jpg'.format(i, category, instance))\n",
    "                    #image_rt_path = join(split_dir, '{:06d}_{}_{:02d}_rt.jpg'.format(i, category, instance))\n",
    "\n",
    "                    y.append(category)\n",
    "                    y.append(category)\n",
    "                    X.append(scipy.misc.imresize(norb_example.image_lt, (w,h)))\n",
    "                    X.append(scipy.misc.imresize(norb_example.image_rt, (w,h)))\n",
    "            print('Done.')\n",
    "            return np.array(X), np.array(y)\n",
    "            \n",
    "    def group_dataset_by_category_and_instance(self, dataset_split):\n",
    "        \"\"\"\n",
    "        Group small NORB dataset for (category, instance) key\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset_split: str\n",
    "            Dataset split, can be either 'train' or 'test'\n",
    "        Returns\n",
    "        -------\n",
    "        groups: list\n",
    "            List of 25 groups of 972 elements each. All examples of each group are\n",
    "            from the same category and instance\n",
    "        \"\"\"\n",
    "        if dataset_split not in ['train', 'test']:\n",
    "            raise ValueError('Dataset split \"{}\" not allowed.'.format(dataset_split))\n",
    "\n",
    "        groups = []\n",
    "        for key, group in groupby(iterable=sorted(self.data[dataset_split]),\n",
    "                                  key=lambda x: (x.category, x.instance)):\n",
    "            groups.append(list(group))\n",
    "\n",
    "        return groups\n",
    "\n",
    "    def _fill_data_structures(self, dataset_split):\n",
    "        \"\"\"\n",
    "        Fill SmallNORBDataset data structures for a certain `dataset_split`.\n",
    "        \n",
    "        This means all images, category and additional information are loaded from binary\n",
    "        files of the current split.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset_split: str\n",
    "            Dataset split, can be either 'train' or 'test'\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        dat_data  = self._parse_NORB_dat_file(self.dataset_files[dataset_split]['dat'])\n",
    "        cat_data  = self._parse_NORB_cat_file(self.dataset_files[dataset_split]['cat'])\n",
    "        info_data = self._parse_NORB_info_file(self.dataset_files[dataset_split]['info'])\n",
    "        for i, small_norb_example in enumerate(self.data[dataset_split]):\n",
    "            small_norb_example.image_lt   = dat_data[2 * i]\n",
    "            small_norb_example.image_rt   = dat_data[2 * i + 1]\n",
    "            small_norb_example.category  = cat_data[i]\n",
    "            small_norb_example.instance  = info_data[i][0]\n",
    "            small_norb_example.elevation = info_data[i][1]\n",
    "            small_norb_example.azimuth   = info_data[i][2]\n",
    "            small_norb_example.lighting  = info_data[i][3]\n",
    "\n",
    "    @staticmethod\n",
    "    def matrix_type_from_magic(magic_number):\n",
    "        \"\"\"\n",
    "        Get matrix data type from magic number\n",
    "        See here: https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/readme for details.\n",
    "        Parameters\n",
    "        ----------\n",
    "        magic_number: tuple\n",
    "            First 4 bytes read from small NORB files \n",
    "        Returns\n",
    "        -------\n",
    "        element type of the matrix\n",
    "        \"\"\"\n",
    "        convention = {'1E3D4C51': 'single precision matrix',\n",
    "                      '1E3D4C52': 'packed matrix',\n",
    "                      '1E3D4C53': 'double precision matrix',\n",
    "                      '1E3D4C54': 'integer matrix',\n",
    "                      '1E3D4C55': 'byte matrix',\n",
    "                      '1E3D4C56': 'short matrix'}\n",
    "        magic_str = bytearray(reversed(magic_number)).hex().upper()\n",
    "        return convention[magic_str]\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_small_NORB_header(file_pointer):\n",
    "        \"\"\"\n",
    "        Parse header of small NORB binary file\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        file_pointer: BufferedReader\n",
    "            File pointer just opened in a small NORB binary file\n",
    "        Returns\n",
    "        -------\n",
    "        file_header_data: dict\n",
    "            Dictionary containing header information\n",
    "        \"\"\"\n",
    "        # Read magic number\n",
    "        magic = struct.unpack('<BBBB', file_pointer.read(4))  # '<' is little endian)\n",
    "\n",
    "        # Read dimensions\n",
    "        dimensions = []\n",
    "        num_dims, = struct.unpack('<i', file_pointer.read(4))  # '<' is little endian)\n",
    "        for _ in range(num_dims):\n",
    "            dimensions.extend(struct.unpack('<i', file_pointer.read(4)))\n",
    "\n",
    "        file_header_data = {'magic_number': magic,\n",
    "                            'matrix_type': SmallNORBDataset.matrix_type_from_magic(magic),\n",
    "                            'dimensions': dimensions}\n",
    "        return file_header_data\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_NORB_cat_file(file_path):\n",
    "        \"\"\"\n",
    "        Parse small NORB category file\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        file_path: str\n",
    "            Path of the small NORB `*-cat.mat` file\n",
    "        Returns\n",
    "        -------\n",
    "        examples: ndarray\n",
    "            Ndarray of shape (24300,) containing the category of each example\n",
    "        \"\"\"\n",
    "        with open(file_path, mode='rb') as f:\n",
    "            header = SmallNORBDataset._parse_small_NORB_header(f)\n",
    "\n",
    "            num_examples, = header['dimensions']\n",
    "\n",
    "            struct.unpack('<BBBB', f.read(4))  # ignore this integer\n",
    "            struct.unpack('<BBBB', f.read(4))  # ignore this integer\n",
    "\n",
    "            examples = np.zeros(shape=num_examples, dtype=np.int32)\n",
    "            for i in tqdm(range(num_examples), desc='Loading categories...'):\n",
    "                category, = struct.unpack('<i', f.read(4))\n",
    "                examples[i] = category\n",
    "\n",
    "            return examples\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_NORB_dat_file(file_path):\n",
    "        \"\"\"\n",
    "        Parse small NORB data file\n",
    "        Parameters\n",
    "        ----------\n",
    "        file_path: str\n",
    "            Path of the small NORB `*-dat.mat` file\n",
    "        Returns\n",
    "        -------\n",
    "        examples: ndarray\n",
    "            Ndarray of shape (48600, 96, 96) containing images couples. Each image couple\n",
    "            is stored in position [i, :, :] and [i+1, :, :]\n",
    "        \"\"\"\n",
    "        with open(file_path, mode='rb') as f:\n",
    "\n",
    "            header = SmallNORBDataset._parse_small_NORB_header(f)\n",
    "\n",
    "            num_examples, channels, height, width = header['dimensions']\n",
    "\n",
    "            examples = np.zeros(shape=(num_examples * channels, height, width), dtype=np.uint8)\n",
    "\n",
    "            for i in tqdm(range(num_examples * channels), desc='Loading images...'):\n",
    "\n",
    "                # Read raw image data and restore shape as appropriate\n",
    "                image = struct.unpack('<' + height * width * 'B', f.read(height * width))\n",
    "                image = np.uint8(np.reshape(image, newshape=(height, width)))\n",
    "\n",
    "                examples[i] = image\n",
    "\n",
    "        return examples\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_NORB_info_file(file_path):\n",
    "        \"\"\"\n",
    "        Parse small NORB information file\n",
    "        Parameters\n",
    "        ----------\n",
    "        file_path: str\n",
    "            Path of the small NORB `*-info.mat` file\n",
    "        Returns\n",
    "        -------\n",
    "        examples: ndarray\n",
    "            Ndarray of shape (24300,4) containing the additional info of each example.\n",
    "            \n",
    "             - column 1: the instance in the category (0 to 9)\n",
    "             - column 2: the elevation (0 to 8, which mean cameras are 30, 35,40,45,50,55,60,65,70 \n",
    "               degrees from the horizontal respectively)\n",
    "             - column 3: the azimuth (0,2,4,...,34, multiply by 10 to get the azimuth in degrees)\n",
    "             - column 4: the lighting condition (0 to 5)\n",
    "        \"\"\"\n",
    "        with open(file_path, mode='rb') as f:\n",
    "\n",
    "            header = SmallNORBDataset._parse_small_NORB_header(f)\n",
    "\n",
    "            struct.unpack('<BBBB', f.read(4))  # ignore this integer\n",
    "\n",
    "            num_examples, num_info = header['dimensions']\n",
    "\n",
    "            examples = np.zeros(shape=(num_examples, num_info), dtype=np.int32)\n",
    "\n",
    "            for r in tqdm(range(num_examples), desc='Loading info...'):\n",
    "                for c in range(num_info):\n",
    "                    info, = struct.unpack('<i', f.read(4))\n",
    "                    examples[r, c] = info\n",
    "\n",
    "        return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images...: 100%|███████████████████████████████████████████████████████| 48600/48600 [00:21<00:00, 2221.48it/s]\n",
      "Loading categories...: 100%|████████████████████████████████████████████████| 24300/24300 [00:00<00:00, 1873868.60it/s]\n",
      "Loading info...: 100%|███████████████████████████████████████████████████████| 24300/24300 [00:00<00:00, 566334.87it/s]\n",
      "Loading images...: 100%|███████████████████████████████████████████████████████| 48600/48600 [00:21<00:00, 2232.81it/s]\n",
      "Loading categories...: 100%|████████████████████████████████████████████████| 24300/24300 [00:00<00:00, 2026072.70it/s]\n",
      "Loading info...: 100%|███████████████████████████████████████████████████████| 24300/24300 [00:00<00:00, 594267.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the dataset from the folder in which\n",
    "# dataset archives have been uncompressed\n",
    "dataset = SmallNORBDataset(dataset_root='./data/smallNORB/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda34\\envs\\gpu_env\\lib\\site-packages\\ipykernel_launcher.py:174: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n",
      "C:\\ProgramData\\Anaconda34\\envs\\gpu_env\\lib\\site-packages\\ipykernel_launcher.py:175: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Dump all images to disk\n",
    "X, y = dataset.get_XY(96, 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97200, 96, 96)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97200,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
